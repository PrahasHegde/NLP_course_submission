# NLP_course_submission

This repository contains the coursework, experiments, and projects submitted as part of the **Natural Language Processing (NLP) course**.

> **Note:** Some files may not be properly visible or opened directly in GitHub's web interface. For the best viewing experience and to access all files properly, we recommend downloading the entire repository.

## Team Members
- **Yashaswini Suresh**
- **Prahas Hegde**
- **Harshith Babu Prakash Babu**
- **Yashwanth Goud Chithaloori**

---

## Team Contributions

**Paper Presentation (Portfolio 1)**
- All team members contributed equally to understanding the paper, preparing slides, and delivering the presentation

**Course Activities (Portfolio 2)**
- Tutorial participation: All members participated equally
- Poetry slam: All members contributed equally
- DAAD Event: Yashaswini Suresh, Yashwanth Goud

**Kaggle Competition (Portfolio 3)**
- All team members contributed equally to data analysis, model development, and experimentation

**Capstone Project (Portfolio 4)**
- All team members contributed equally to ideation, implementation, prototype development, and integrating course concepts
---

## Repository Structure

The repository is organized into multiple portfolios covering theoretical understanding, practical implementations, competitions, and a capstone project.

### 1️⃣ Paper Presentation (Portfolio 1)
- **Folder:** `1.Paper_presentation .zip`
  - Contains the research paper: "A SIMPLE BUT TOUGH-TO-BEAT BASELINE FOR SENTENCE EMBEDDINGS"
  - Includes presentation deck (PDF) summarizing the concepts, methodology, and results

### 2️⃣ Course Activities (Portfolio 2)
- **Folder:** `2.Course_Activities(tutorial, poetry slam, DAAD Event).zip`
  - **Subfolders:**
    - `Course Activities/DaaD event/` - Materials and code from DAAD Event participation
    - `Course Activities/Poem_generater_bot-main/` - Poem generation bot project
      - Contains: `.gitignore`, `main.py`, `muse.py`, `README.md`
    - `Fine_tuning_a_masked_language_model_(PyTorch).ipynb` - Tutorial work on fine-tuning MLM using Hugging Face

### 3️⃣ Kaggle Competition (Portfolio 3)
- **Folder:** `3.Tunix_Kaggel_competation.zip`
  - **Subfolder:** `Kaggel_Tunix/`
  - Contains:
    - `Gemma2_ARC_dataset.ipynb` - Jupyter notebook with competition code
    - `Results_1.png`, `Results_2.png`, `2.png`, `1.png` - Competition results and visualizations
    - `README.md` - Documentation for the competition approach

### 4️⃣ Capstone Project (Portfolio 4)
- **Folder:** `4.capstone_project.zip`
  - **Project:** CareerForge AI-cyber
  - An intelligent career optimization platform powered by Llama-3 and Groq
  - Features:
    - Advanced RAG (Retrieval Augmented Generation) for resume analysis
    - Live company intelligence integration
    - Interactive skill visualization
    - Helps bridge the gap between resumes and dream jobs
  - **Files:**
    - `src/` - Source code directory containing:
      - `graph_builder.py` - Graph construction module
      - `llm_engine.py` - LLM integration engine
      - `pdf_gen.py` - PDF generation utilities
      - `pdf_handler.py` - PDF processing module
      - `ui_styles.py` - UI styling components
      - `web_search.py` - Web search functionality
    - `index.py` - Main Streamlit application file
    - `main.py` - Application entry point
    - `requirements.txt` - Python dependencies
    - `README.md` - Project documentation
    - `CareerForge AI_ppt.pdf` - Project presentation
  
### 5️⃣ README File
- **File:** `README.md`
- Main documentation file for the repository (this file)

---

## Technologies & Tools Used
- Python
- PyTorch
- Hugging Face Transformers
- Jupyter Notebook
- NLP libraries (NLTK, spaCy, etc.)
- Kaggle

---

## Notes
- Each folder or file is self-contained and corresponds to a specific course requirement.
- Please refer to individual notebooks or documents for detailed explanations and results.
- All team members worked collaboratively throughout the project.

---

## License
This repository is intended for **academic and educational purposes only**.
